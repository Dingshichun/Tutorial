# 模型量化
## 1、为什么需要量化？
把 float(FP32/FP16) 类型的模型参数和激活值，用整型(int8/int4)来表示  
同时尽可能减少量化后模型推理的误差。
带来的好处：
* 减少模型的存储空间和显存的占用。
* 减少显存和 TensorCore 之间的数据传输量，从而加快模型推理时间。
* 对于显卡来说，计算整数比浮点型数要快，以此加快模型推理时间。

